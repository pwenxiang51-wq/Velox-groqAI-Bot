/**
 * âš¡ Velo.x AI - v7.0 (Final Translation Edition)
 * ---------------------------------------------
 * æ ¸å¿ƒä¿®å¤ï¼šå¢åŠ äº†â€œè‡ªåŠ¨ç¿»è¯‘â€å±‚ã€‚
 * é€»è¾‘ï¼šç”¨æˆ·è¾“å…¥ä¸­æ–‡ -> Groq ç¿»è¯‘æˆè‹±æ–‡ -> SDXL ç”»å›¾ã€‚
 * è§£å†³ï¼šå½»åº•è§£å†³ SDXL å¬ä¸æ‡‚ä¸­æ–‡å¯¼è‡´ç”»å‡ºé£æ™¯æˆ–ä¹±ç çš„é—®é¢˜ã€‚
 */

const CONFIG = {
    TEXT_MODEL: 'llama-3.1-8b-instant', 
    SYSTEM_PROMPT: `You are a helpful assistant. Answer concisely in Chinese.`,
    MEMORY_LIMIT: 10,
    IMAGE_MODEL: '@cf/stabilityai/stable-diffusion-xl-base-1.0'
  };
  
  export default {
    async fetch(request, env) {
        if (request.method !== 'POST') return new Response('System Online.', { status: 200 });
  
        try {
            const update = await request.json();
            if (!update.message || !update.message.text) return new Response('OK');
  
            const chatId = update.message.chat.id;
            const userId = update.message.from.id;
            const text = update.message.text.trim();
            const messageId = update.message.message_id;
  
            if (env.ADMIN_ID && String(userId) !== String(env.ADMIN_ID)) return new Response('OK'); 
  
            // ğŸ§¹ æ¸…é™¤è®°å¿†
            if (text === '/clear' || text === '/reset') {
                try {
                    await env.MEMORY.delete(String(chatId));
                    await sendText(chatId, "ğŸ§¹ è®°å¿†å·²æ¸…é™¤ã€‚", env);
                } catch (e) {}
                return new Response('OK');
            }
  
            // ğŸ¨ ç»˜å›¾æŒ‡ä»¤ (è‡ªåŠ¨ç¿»è¯‘ç‰ˆ)
            if (text.startsWith('/img') || text.startsWith('/draw')) {
                const rawPrompt = text.replace(/^\/(img|draw)\s*/, '');
                if (!rawPrompt) {
                    await sendText(chatId, "âš ï¸ è¯·è¾“å…¥å†…å®¹ï¼Œä¾‹å¦‚ï¼š`/img ä¸€åªç‹—`", env);
                    return new Response('OK');
                }
                await sendChatAction(chatId, 'upload_photo', env);
                await handleImageGeneration(chatId, rawPrompt, messageId, env);
            } 
            
            // ğŸ’¬ å¯¹è¯æŒ‡ä»¤
            else {
                await sendChatAction(chatId, 'typing', env);
                let history = [];
                try { history = await env.MEMORY.get(String(chatId), { type: 'json' }) || []; } catch (e) { history = []; }
                
                const requestMessages = [...history, { role: "user", content: text }];
                const aiReply = await fetchGroq(requestMessages, env); // å¤ç”¨é€šç”¨è¯·æ±‚å‡½æ•°
                
                await sendText(chatId, aiReply, env, messageId);
  
                try {
                    history.push({ role: "user", content: text });
                    history.push({ role: "assistant", content: aiReply });
                    if (history.length > CONFIG.MEMORY_LIMIT) history = history.slice(history.length - CONFIG.MEMORY_LIMIT);
                    await env.MEMORY.put(String(chatId), JSON.stringify(history));
                } catch (e) { }
            }
  
        } catch (e) { console.error(e); }
        return new Response('OK');
    }
  };
  
  // ==========================================
  // ğŸ§  Groq é€šç”¨è¯·æ±‚ (å¯¹è¯ & ç¿»è¯‘)
  // ==========================================
  async function fetchGroq(messages, env) {
    try {
        const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${env.GROQ_API_KEY}`
            },
            body: JSON.stringify({
                model: CONFIG.TEXT_MODEL,
                messages: messages,
                temperature: 0.6,
                max_tokens: 1024
            })
        });
        const data = await response.json();
        return data.choices?.[0]?.message?.content || "âŒ æ— å“åº”";
    } catch (e) { return `Error: ${e.message}`; }
  }
  
  // ==========================================
  // ğŸ¨ AI ç»˜å›¾ (å¸¦è‡ªåŠ¨ç¿»è¯‘åŠŸèƒ½)
  // ==========================================
  async function handleImageGeneration(chatId, rawPrompt, replyId, env) {
    try {
        // 1. å…³é”®æ­¥éª¤ï¼šå…ˆæ‰¾ Groq æŠŠä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡ Prompt
        // å‘Šè¯‰ Groqï¼šä½ æ˜¯ç¿»è¯‘å®˜ï¼Œåªè¾“å‡ºè‹±æ–‡ï¼Œä¸è¦åºŸè¯ã€‚
        const transMessages = [
            { 
                role: "system", 
                // ğŸ‘‡ğŸ‘‡ğŸ‘‡ æ ¸å¿ƒä¿®æ”¹ï¼šåŠ äº†ä¸‰é“é‡‘ç‰Œä»¤ç®­ï¼Œç¦æ­¢è¾“å‡ºä¸­æ–‡ ğŸ‘‡ğŸ‘‡ğŸ‘‡
                content: "You are an expert AI photographer. Your task is to rewrite the user's input into a detailed, photorealistic ENGLISH prompt. \n\nRULES:\n1. Output MUST be in English.\n2. NO Chinese characters allowed in output.\n3. Focus on lighting, texture, and realism." 
            },
            { role: "user", content: rawPrompt }
        ];
        
        // è·å–ç¿»è¯‘ç»“æœ (ä¾‹å¦‚ï¼š'ä¸€åªç‹—' -> 'A cute dog sitting on floor...')
        let englishPrompt = await fetchGroq(transMessages, env);
        
        // å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹è¾“å…¥
        if (englishPrompt.includes("Error") || englishPrompt.includes("æ— å“åº”")) {
            englishPrompt = rawPrompt; 
        }
  
        // 2. å°†è‹±æ–‡ Prompt ä¼ ç»™ SDXL
        const inputs = { prompt: englishPrompt, num_steps: 20 }; 
        const responseStream = await env.AI.run(CONFIG.IMAGE_MODEL, inputs);
  
        const arrayBuffer = await new Response(responseStream).arrayBuffer();
        const blob = new Blob([arrayBuffer], { type: 'image/png' });
  
        const formData = new FormData();
        formData.append('chat_id', chatId);
        formData.append('photo', blob, 'gen.png'); 
        // 3. å›å¤æ—¶æ˜¾ç¤º ç¿»è¯‘åçš„è‹±æ–‡æç¤ºè¯ï¼Œè®©ä½ çŸ¥é“å®ƒç†è§£äº†ä»€ä¹ˆ
        formData.append('caption', `ğŸ¨ ç»˜å›¾å®Œæˆ\nåŸè¯: ${rawPrompt}\nAIç†è§£: \`${englishPrompt}\``);
        formData.append('parse_mode', 'Markdown');
        formData.append('reply_to_message_id', replyId);
  
        const res = await fetch(`https://api.telegram.org/bot${env.TG_BOT_TOKEN}/sendPhoto`, {
            method: 'POST',
            body: formData
        });
        
        if (!res.ok) throw new Error("TG å‘é€å¤±è´¥");
  
    } catch (err) {
        await sendText(chatId, `âŒ **ç»˜å›¾å¤±è´¥:** ${err.message}`, env);
    }
  }
  
  // ==========================================
  // ğŸ› ï¸ è¾…åŠ©å·¥å…·
  // ==========================================
  async function sendChatAction(chatId, action, env) {
    try {
        await fetch(`https://api.telegram.org/bot${env.TG_BOT_TOKEN}/sendChatAction`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ chat_id: chatId, action: action })
        });
    } catch (e) {}
  }
  
  async function sendText(chatId, text, env, replyId = null) {
    const url = `https://api.telegram.org/bot${env.TG_BOT_TOKEN}/sendMessage`;
    const payload = { chat_id: chatId, text: text, parse_mode: 'Markdown', reply_to_message_id: replyId };
    let res = await fetch(url, { method: 'POST', headers: {'Content-Type': 'application/json'}, body: JSON.stringify(payload) });
    if (!res.ok) {
        delete payload.parse_mode;
        await fetch(url, { method: 'POST', headers: {'Content-Type': 'application/json'}, body: JSON.stringify(payload) });
    }
  }
